{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034eea5ec0346b2263b8e3f93f6c7ea5",
   "metadata": {},
   "source": [
    "# MNIST: Digits Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dc0eeb094f7cfd845c677651c20f1",
   "metadata": {
    "tags": [
     "add-colab-badge"
    ]
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unionai-oss/unionml/blob/main/docs/notebooks/mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fdcf8ab8da049320be6ec4fcdaec2",
   "metadata": {},
   "source": [
    "The MNIST dataset is considered to be the \"hello world\" example of machine\n",
    "learning. In that same spirit, we'll be making the \"hello world\" UnionML app\n",
    "using this dataset and a simple linear classifier with\n",
    "[sklearn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "With this dataset, we'll see just how easy it is to create a single-script UnionML app.\n",
    "\n",
    "```{note}\n",
    "This tutorial is adapted from this [sklearn guide](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c482e9ff037fa3d4cce5dbb83fee6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install 'gradio<=3.0.10' pandas sklearn unionml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff842342950d50d88a1c53c27d6544",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "> If you're running this notebook in google colab, you need to restart the kernel to\n",
    "> make sure that the newly installed packages are correctly imported in the next line below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d4e5d139b4c33197ac4eef2dd276f",
   "metadata": {},
   "source": [
    "First let's import our dependencies and create the UnionML `Dataset` and `Model`\n",
    "objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae76e972ae855183fdf538045140c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from unionml import Dataset, Model\n",
    "\n",
    "\n",
    "dataset = Dataset(name=\"mnist_dataset\", test_size=0.2, shuffle=True, targets=[\"class\"])\n",
    "model = Model(name=\"mnist_classifier\", init=LogisticRegression, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13225beaa5c15218d0a44dc218937df",
   "metadata": {},
   "source": [
    "For convenience, we cache the dataset so that MNIST loading is faster upon subsequent calls\n",
    "to the `fetch_openml` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24d818acd8ea213ea7a201860ac7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(Path.home() / \"tmp\")\n",
    "fetch_openml_cached = memory.cache(fetch_openml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7752310d1a3b3dc4ae11269993de3",
   "metadata": {},
   "source": [
    "Next, we define our core UnionML app functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb631bb66e19de52dfd20929137e683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataset.reader(cache=True, cache_version=\"1\")\n",
    "def reader() -> pd.DataFrame:\n",
    "    dataset = fetch_openml_cached(\n",
    "        \"mnist_784\",\n",
    "        version=1,\n",
    "        cache=True,\n",
    "        as_frame=True,\n",
    "    )\n",
    "    # randomly sample a subset for faster training\n",
    "    return dataset.frame.sample(1000, random_state=42)\n",
    "\n",
    "\n",
    "@model.init\n",
    "def init(hyperparameters: dict) -> Pipeline:\n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    "    return estimator.set_params(**hyperparameters)\n",
    "\n",
    "\n",
    "@model.trainer(cache=True, cache_version=\"1\")\n",
    "def trainer(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> Pipeline:\n",
    "    return estimator.fit(features, target.squeeze())\n",
    "\n",
    "\n",
    "@model.predictor\n",
    "def predictor(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    ") -> List[float]:\n",
    "    return [float(x) for x in estimator.predict(features)]\n",
    "\n",
    "\n",
    "@model.evaluator\n",
    "def evaluator(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> float:\n",
    "    return float(accuracy_score(target.squeeze(), estimator.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3668b46fa9ead5032efc07adf023a0",
   "metadata": {},
   "source": [
    "## Training a Model Locally\n",
    "\n",
    "Then we can train our model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937dc1f58584d18238f25840d322f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, metrics = model.train(\n",
    "    hyperparameters={\n",
    "        \"classifier__penalty\": \"l2\",\n",
    "        \"classifier__C\": 0.1,\n",
    "        \"classifier__max_iter\": 1000,\n",
    "    }\n",
    ")\n",
    "features = reader().sample(5, random_state=42).drop([\"class\"], axis=\"columns\")\n",
    "print(estimator, metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9329aa0a08d2e8545919602c56ad5",
   "metadata": {},
   "source": [
    "## Serving on a Gradio Widget\n",
    "\n",
    "Finally, let's create a `gradio` widget by simply using the `model.predict` method into\n",
    "the `gradio.Interface` object.\n",
    "\n",
    "Before we do this, however, we want to define a `feature_loader` function to handle the raw input\n",
    "coming from the `gradio` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b94022bf76842ede4ef3f72f19c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataset.feature_loader\n",
    "def feature_loader(data: np.ndarray) -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.DataFrame(data.ravel())\n",
    "        .transpose()\n",
    "        .rename(columns=lambda x: f\"pixel{x + 1}\")\n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86361b76b70831d2df155024d024ea91",
   "metadata": {},
   "source": [
    "We also need to take care to handle the `None` case when we press\n",
    "the `clear` button on the widget using a `lambda` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa6cb92d0f9102918061f05731f92e",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=lambda img: img if img is None else model.predict(img)[0],\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f8cb8c333ccce89be67fd6b99f685",
   "metadata": {},
   "source": [
    "You might notice that the model may not perform as well as you might expect...\n",
    "welcome to the world of machine learning practice! To obtain a better model given\n",
    "a fixed dataset, feel free to play around with the model hyperparameters or even\n",
    "switch up the model type/architecture that's defined in the `trainer` function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
